{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import math as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Converts WALS coordinate data n to nearest n.25 or n.75 in order to search for classification\n",
    "def rco(num):\n",
    "    n = num-int(num)\n",
    "    if n<=0.5:\n",
    "        return (int(num)+ 0.25)\n",
    "    else:\n",
    "        return(int(num)+0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Auxilary binary search function\n",
    "def binary(alist, item):\n",
    "    if len(alist) == 0:\n",
    "        return (-1)\n",
    "    else:\n",
    "        midpoint = len(alist)//2\n",
    "        if alist[midpoint]==item:\n",
    "          return (midpoint)\n",
    "        else:\n",
    "          if item<alist[midpoint]:\n",
    "            return binary(alist[:midpoint],item)\n",
    "          else:\n",
    "            return binary(alist[midpoint+1:],item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Spent a lot of the time finding the encoding\n",
    "lang_df = pd.read_csv('language.csv', encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#koppen_1901-2010.tsv contains a file with latitude and longitudes that are close to .25 and .75 that gives the climate\n",
    "koppen = np.genfromtxt(\"koppen_1901-2010.tsv\", dtype=None, names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Translate longitude and latitude to Climate use binary search to look for num. coordinates\n",
    "Clim = []\n",
    "for i in range(0, len(lang_df)):\n",
    "    s = 0\n",
    "    if rco(lang_df['longitude'][i]) == -179.75:\n",
    "        s = 0\n",
    "    else:\n",
    "        #binary search in first columns\n",
    "        long = rco(lang_df['longitude'][i]) - 0.5\n",
    "        s = binary(koppen['longitude'],long)\n",
    "    \n",
    "    if s==-1:\n",
    "            Clim.append(str(\"NaN\"))\n",
    "            print(i)\n",
    "    else:\n",
    "        j=s\n",
    "        lat = rco(lang_df['latitude'][i])\n",
    "        lon = rco(lang_df['longitude'][i])\n",
    "        \n",
    "        while bool(lat == koppen['latitude'][j] and lon== koppen['longitude'][j])==False and bool(koppen['longitude'][j]< lon+1)==True:\n",
    "            j=j+1\n",
    "            if j== len(koppen['latitude'])-1:\n",
    "                break\n",
    "        \n",
    "        if rco(lang_df['latitude'][i])== koppen['latitude'][j] and rco(lang_df['longitude'][i])==koppen['longitude'][j]:\n",
    "            Clim.append(str(koppen['p1901_2010'][j]))\n",
    "        else:\n",
    "            Clim.append(\"NaN\")\n",
    "                                                                       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = np.asarray(Clim)\n",
    "#lang_df[\"Climate\"] = k\n",
    "# drop languages that where unale to be classified with Koppen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reducing rows to those containing features with all values\n",
    "df1 = lang_df[lang_df['1A_Consonant_Inventories'].notnull() & lang_df['2A_Vowel_Quality_Inventories'].notnull() & lang_df['3A_Consonant-Vowel_Ratio'].notnull() & lang_df['4A_Voicing_in_Plosives_and_Fricatives'].notnull()& lang_df['13A_Tone'].notnull() \n",
    "& lang_df['18A_Absence_of_Common_Consonants'].notnull() & lang_df['7A_Glottalized_Consonants'].notnull() & lang_df['8A_Lateral_Consonants'].notnull() & lang_df['9A_The_Velar_Nasal'].notnull()& lang_df['10A_Vowel_Nasalization'].notnull()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Pre-processing  - features into numeric values\n",
    "\n",
    "f1 = df1['1A_Consonant_Inventories'].str[0]\n",
    "f1 = pd.to_numeric(f1)\n",
    "f2 = df1['2A_Vowel_Quality_Inventories'].str[0]\n",
    "f2 = pd.to_numeric(f2)\n",
    "f3 = df1['3A_Consonant-Vowel_Ratio'].str[0]\n",
    "f3 = pd.to_numeric(f3)\n",
    "f4 = df1['4A_Voicing_in_Plosives_and_Fricatives'].str[0]\n",
    "f4 = pd.to_numeric(f4)\n",
    "f5 = df1['13A_Tone'].str[0]\n",
    "f5 = pd.to_numeric(f5)\n",
    "                   \n",
    "f6 = df1['18A_Absence_of_Common_Consonants'].str[0]\n",
    "f6 = pd.to_numeric(f6)\n",
    "f7 = df1['7A_Glottalized_Consonants'].str[0]\n",
    "f7 = pd.to_numeric(f7)\n",
    "f8 = df1['8A_Lateral_Consonants'].str[0]\n",
    "f8 = pd.to_numeric(f8)\n",
    "f9 = df1['9A_The_Velar_Nasal'].str[0]\n",
    "f9 = pd.to_numeric(f9)\n",
    "f10 = df1['10A_Vowel_Nasalization'].str[0]\n",
    "f10 = pd.to_numeric(f10)\n",
    "\n",
    "#convert all series to list data structures\n",
    "f1 = pd.Series.tolist(f1)\n",
    "f2 = pd.Series.tolist(f2)\n",
    "f3 = pd.Series.tolist(f3)\n",
    "f4 = pd.Series.tolist(f4)\n",
    "f5 = pd.Series.tolist(f5)\n",
    "f6 = pd.Series.tolist(f6)\n",
    "f7 = pd.Series.tolist(f7)\n",
    "f8 = pd.Series.tolist(f8)\n",
    "f9 = pd.Series.tolist(f9)\n",
    "f10 = pd.Series.tolist(f10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#turn series into an array of samples, where each list consist of different types of languages\n",
    "X = []\n",
    "f1 = pd.Series.tolist(f1)\n",
    "for i in range(0, len(f1)):\n",
    "    X.append([])\n",
    "for i in range(0, len(f1)):\n",
    "    X[i].append(f1[i])\n",
    "    X[i].append(f2[i])\n",
    "    X[i].append(f3[i])\n",
    "    X[i].append(f4[i])\n",
    "    X[i].append(f5[i])\n",
    "    X[i].append(f6[i])\n",
    "    X[i].append(f7[i])\n",
    "    X[i].append(f8[i])\n",
    "    X[i].append(f9[i])\n",
    "    X[i].append(f10[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Convert koppen classification columns into numerical category by first letter\n",
    "Y = pd.Series.tolist(df1['Climate'])\n",
    "for i in range(0,len(Y)):\n",
    "    if Y[i][2] == 'A':\n",
    "        Y[i] = 1\n",
    "    elif Y[i][2] == 'B':\n",
    "        Y[i] = 2\n",
    "    elif Y[i][2] == 'C':\n",
    "        Y[i] = 3\n",
    "    elif Y[i][2] == 'D':\n",
    "        Y[i] = 4\n",
    "    elif Y[i][2] == 'E':\n",
    "        Y[i] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#run SVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "classif = OneVsRestClassifier(estimator=SVC(random_state=0))\n",
    "\n",
    "pred = classif.fit(X, Y).predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   1   2   3  4  5\n",
       "Actual                     \n",
       "1          43   1   1  0  0\n",
       "2          12  10   5  0  0\n",
       "3           7   2  22  3  0\n",
       "4           6   0   4  8  0\n",
       "5           0   0   0  0  4"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix for SVC\n",
    "y_actu = pd.Series(Y, name='Actual')\n",
    "y_pred = pd.Series(pred, name='Predicted')\n",
    "df_confusion = pd.crosstab(y_actu, y_pred)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted         1         2         3         4    5\n",
       "Actual                                                \n",
       "1          0.955556  0.037037  0.029412  0.000000  0.0\n",
       "2          0.266667  0.370370  0.147059  0.000000  0.0\n",
       "3          0.155556  0.074074  0.647059  0.166667  0.0\n",
       "4          0.133333  0.000000  0.117647  0.444444  0.0\n",
       "5          0.000000  0.000000  0.000000  0.000000  1.0"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalized confusion matrix\n",
    "df_conf_norm = df_confusion / df_confusion.sum(axis=1)\n",
    "df_conf_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6796875"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Simple accuracy measurement\n",
    "c=0\n",
    "for i in range(0, len(Y)):\n",
    "    if Y[i]== pred[i]:\n",
    "        c=c+1\n",
    "c/len(Y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55033844572016111"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cohen's Kappa Score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "cohen_kappa_score(y_actu, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
