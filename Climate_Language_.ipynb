{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Project for Quantitative Criticism Lab (UT Austin)\n",
    "#Elias Sanchez\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import math as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Converts WALS coordinate data n to nearest n.25 or n.75 in order to search for classification\n",
    "def rco(num):\n",
    "    n = num-int(num)\n",
    "    if n<=0.5:\n",
    "        return (int(num)+ 0.25)\n",
    "    else:\n",
    "        return(int(num)+0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Auxilary binary search function\n",
    "def binary(alist, item):\n",
    "    if len(alist) == 0:\n",
    "        return (-1)\n",
    "    else:\n",
    "        midpoint = len(alist)//2\n",
    "        if alist[midpoint]==item:\n",
    "          return (midpoint)\n",
    "        else:\n",
    "          if item<alist[midpoint]:\n",
    "            return binary(alist[:midpoint],item)\n",
    "          else:\n",
    "            return binary(alist[midpoint+1:],item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lang_df = pd.read_csv('language.csv', encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#koppen_1901-2010.tsv contains a file with latitude and longitudes that are close to .25 and .75 that gives the climate\n",
    "koppen = np.genfromtxt(\"koppen_1901-2010.tsv\", dtype=None, names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Translate longitude and latitude to Climate use binary search to look for num. coordinates\n",
    "Clim = []\n",
    "for i in range(0, len(lang_df)):\n",
    "    s = 0\n",
    "    if rco(lang_df['longitude'][i]) == -179.75:\n",
    "        s = 0\n",
    "    else:\n",
    "        #binary search in first columns\n",
    "        long = rco(lang_df['longitude'][i]) - 0.5\n",
    "        s = binary(koppen['longitude'],long)\n",
    "    \n",
    "    if s==-1:\n",
    "            Clim.append(str(\"NaN\"))\n",
    "            print(i)\n",
    "    else:\n",
    "        j=s\n",
    "        lat = rco(lang_df['latitude'][i])\n",
    "        lon = rco(lang_df['longitude'][i])\n",
    "        \n",
    "        while bool(lat == koppen['latitude'][j] and lon== koppen['longitude'][j])==False and bool(koppen['longitude'][j]< lon+1)==True:\n",
    "            j=j+1\n",
    "            if j== len(koppen['latitude'])-1:\n",
    "                break\n",
    "        \n",
    "        if rco(lang_df['latitude'][i])== koppen['latitude'][j] and rco(lang_df['longitude'][i])==koppen['longitude'][j]:\n",
    "            Clim.append(str(koppen['p1901_2010'][j]))\n",
    "        else:\n",
    "            Clim.append(\"NaN\")\n",
    "                                                                       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = np.asarray(Clim)\n",
    "#lang_df[\"Climate\"] = k\n",
    "# drop languages that where unale to be classified with Koppen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Testing features on Phonology Area \n",
    "df1 = lang_df[lang_df['1A_Consonant_Inventories'].notnull() & lang_df['2A_Vowel_Quality_Inventories'].notnull() & lang_df['3A_Consonant-Vowel_Ratio'].notnull() & lang_df['4A_Voicing_in_Plosives_and_Fricatives'].notnull()& lang_df['13A_Tone'].notnull() \n",
    "& lang_df['18A_Absence_of_Common_Consonants'].notnull() & lang_df['7A_Glottalized_Consonants'].notnull() & lang_df['8A_Lateral_Consonants'].notnull() & lang_df['9A_The_Velar_Nasal'].notnull()& lang_df['10A_Vowel_Nasalization'].notnull()]\n",
    "features = ['1A_Consonant_Inventories', '2A_Vowel_Quality_Inventories', '3A_Consonant-Vowel_Ratio', '4A_Voicing_in_Plosives_and_Fricatives', '13A_Tone', '18A_Absence_of_Common_Consonants', '7A_Glottalized_Consonants', '8A_Lateral_Consonants', '9A_The_Velar_Nasal', '10A_Vowel_Nasalization']\n",
    "col = ['Name', '1A_Consonant_Inventories', '2A_Vowel_Quality_Inventories', '3A_Consonant-Vowel_Ratio', '4A_Voicing_in_Plosives_and_Fricatives', '13A_Tone', '18A_Absence_of_Common_Consonants', '7A_Glottalized_Consonants', '8A_Lateral_Consonants', '9A_The_Velar_Nasal', '10A_Vowel_Nasalization', 'Climate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A - Tropical: 1036\n",
      "B - Arid: 344\n",
      "C - Temperate: 553\n",
      "D - Cold: 234\n",
      "E - Polar: 68\n"
     ]
    }
   ],
   "source": [
    "#Basic Ststistic - Distribution of Climate languages\n",
    "lang_df['Climate']\n",
    "A=0\n",
    "B=0\n",
    "C=0\n",
    "D=0\n",
    "E=0\n",
    "Cl= pd.Series.tolist(lang_df['Climate'])\n",
    "for i in range(0,len(Cl)):\n",
    "    if Cl[i][2] == 'A':\n",
    "        A+=1\n",
    "    elif Cl[i][2] == 'B':\n",
    "        B+=1\n",
    "    elif Cl[i][2] == 'C':\n",
    "        C+=1\n",
    "    elif Cl[i][2] == 'D':\n",
    "        D+=1\n",
    "    elif Cl[i][2] == 'E':\n",
    "        E+=1\n",
    "print(\"A - Tropical: \" + str(A) )\n",
    "print(\"B - Arid: \" + str(B) )\n",
    "print(\"C - Temperate: \" + str(C) )\n",
    "print(\"D - Cold: \" + str(D) )\n",
    "print(\"E - Polar: \" + str(E) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Pre-processing  - features into numeric values\n",
    "\n",
    "f1 = df1['1A_Consonant_Inventories'].str[0]\n",
    "f1 = pd.to_numeric(f1)\n",
    "f2 = df1['2A_Vowel_Quality_Inventories'].str[0]\n",
    "f2 = pd.to_numeric(f2)\n",
    "f3 = df1['3A_Consonant-Vowel_Ratio'].str[0]\n",
    "f3 = pd.to_numeric(f3)\n",
    "f4 = df1['4A_Voicing_in_Plosives_and_Fricatives'].str[0]\n",
    "f4 = pd.to_numeric(f4)\n",
    "f5 = df1['13A_Tone'].str[0]\n",
    "f5 = pd.to_numeric(f5)\n",
    "                   \n",
    "f6 = df1['18A_Absence_of_Common_Consonants'].str[0]\n",
    "f6 = pd.to_numeric(f6)\n",
    "f7 = df1['7A_Glottalized_Consonants'].str[0]\n",
    "f7 = pd.to_numeric(f7)\n",
    "f8 = df1['8A_Lateral_Consonants'].str[0]\n",
    "f8 = pd.to_numeric(f8)\n",
    "f9 = df1['9A_The_Velar_Nasal'].str[0]\n",
    "f9 = pd.to_numeric(f9)\n",
    "f10 = df1['10A_Vowel_Nasalization'].str[0]\n",
    "f10 = pd.to_numeric(f10)\n",
    "\n",
    "#convert all series to list data structures\n",
    "f1 = pd.Series.tolist(f1)\n",
    "f2 = pd.Series.tolist(f2)\n",
    "f3 = pd.Series.tolist(f3)\n",
    "f4 = pd.Series.tolist(f4)\n",
    "f5 = pd.Series.tolist(f5)\n",
    "f6 = pd.Series.tolist(f6)\n",
    "f7 = pd.Series.tolist(f7)\n",
    "f8 = pd.Series.tolist(f8)\n",
    "f9 = pd.Series.tolist(f9)\n",
    "f10 = pd.Series.tolist(f10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Matrix of features - turn series into an array of samples, where each list consist of different types of languages\n",
    "X = []\n",
    "f1 = pd.Series.tolist(f1)\n",
    "for i in range(0, len(f1)):\n",
    "    X.append([])\n",
    "for i in range(0, len(f1)):\n",
    "    X[i].append(f1[i])\n",
    "    X[i].append(f2[i])\n",
    "    X[i].append(f3[i])\n",
    "    X[i].append(f4[i])\n",
    "    X[i].append(f5[i])\n",
    "    X[i].append(f6[i])\n",
    "    X[i].append(f7[i])\n",
    "    X[i].append(f8[i])\n",
    "    X[i].append(f9[i])\n",
    "    X[i].append(f10[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Label Encoding\n",
    "#Convert koppen classification columns into numerical category by first letter\n",
    "Y = pd.Series.tolist(df1['Climate'])\n",
    "for i in range(0,len(Y)):\n",
    "    if Y[i][2] == 'A':\n",
    "        Y[i] = 1\n",
    "    elif Y[i][2] == 'B':\n",
    "        Y[i] = 2\n",
    "    elif Y[i][2] == 'C':\n",
    "        Y[i] = 3\n",
    "    elif Y[i][2] == 'D':\n",
    "        Y[i] = 4\n",
    "    elif Y[i][2] == 'E':\n",
    "        Y[i] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#run SVC - One-vs.-rest\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "classif = OneVsRestClassifier(estimator=SVC(random_state=0))\n",
    "\n",
    "pred = classif.fit(X, Y).predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   1   2   3  4  5\n",
       "Actual                     \n",
       "1          43   1   1  0  0\n",
       "2          12  10   5  0  0\n",
       "3           7   2  22  3  0\n",
       "4           6   0   4  8  0\n",
       "5           0   0   0  0  4"
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix for SVC\n",
    "y_actu = pd.Series(Y, name='Actual')\n",
    "y_pred = pd.Series(pred, name='Predicted')\n",
    "df_confusion = pd.crosstab(y_actu, y_pred)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted         1         2         3         4    5\n",
       "Actual                                                \n",
       "1          0.955556  0.037037  0.029412  0.000000  0.0\n",
       "2          0.266667  0.370370  0.147059  0.000000  0.0\n",
       "3          0.155556  0.074074  0.647059  0.166667  0.0\n",
       "4          0.133333  0.000000  0.117647  0.444444  0.0\n",
       "5          0.000000  0.000000  0.000000  0.000000  1.0"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalized confusion matrix\n",
    "df_conf_norm = df_confusion / df_confusion.sum(axis=1)\n",
    "df_conf_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6796875"
      ]
     },
     "execution_count": 785,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Simple accuracy measurement\n",
    "c=0\n",
    "for i in range(0, len(Y)):\n",
    "    if Y[i]== pred[i]:\n",
    "        c=c+1\n",
    "c/len(Y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55033844572016111"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cohen's Kappa Score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "cohen_kappa_score(y_actu, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Random Forest Classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cross_validation import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RFC (features, target):\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(features, target)\n",
    "    return (clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 766,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model = RFC(train_x, train_y)\n",
    "trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy ::  0.916666666667\n",
      "Test Accuracy  ::  0.3125\n"
     ]
    }
   ],
   "source": [
    "predictions = trained_model.predict(test_x)\n",
    "print(\"Train Accuracy :: \", accuracy_score(train_y, trained_model.predict(train_x)))\n",
    "print(\"Test Accuracy  :: \", accuracy_score(test_y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  1  2  3  4\n",
       "Actual               \n",
       "1          7  2  1  1\n",
       "2          1  2  2  2\n",
       "3          3  3  1  3\n",
       "4          1  0  1  0\n",
       "5          0  0  2  0"
      ]
     },
     "execution_count": 768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix for tested sample\n",
    "y_actu = pd.Series(test_y, name='Actual')\n",
    "y_pred = pd.Series(predictions, name='Predicted')\n",
    "df_confusion = pd.crosstab(y_actu, y_pred)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1A_Consonant_Inventories', 0.17187568013835278),\n",
       " ('2A_Vowel_Quality_Inventories', 0.09987693302197484),\n",
       " ('3A_Consonant-Vowel_Ratio', 0.12103710460349355),\n",
       " ('4A_Voicing_in_Plosives_and_Fricatives', 0.14289997460456302),\n",
       " ('13A_Tone', 0.090649478115619991),\n",
       " ('18A_Absence_of_Common_Consonants', 0.023427335019303618),\n",
       " ('7A_Glottalized_Consonants', 0.091759718133277018),\n",
       " ('8A_Lateral_Consonants', 0.12581729654314888),\n",
       " ('9A_The_Velar_Nasal', 0.080932852208196251),\n",
       " ('10A_Vowel_Nasalization', 0.051723627612070035)]"
      ]
     },
     "execution_count": 771,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature Importance\n",
    "list(zip(features, trained_model.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#PREPROCCESSING FOR MORPHOLOGY\n",
    "#Same classification procedure for 8 Morphology Features - 23A, 24A, 25A, 25B, 26A, 27A, 28A, 29A\n",
    "df2 = lang_df[lang_df['23A_Locus_of_Marking_in_the_Clause'].notnull() & lang_df['24A_Locus_of_Marking_in_Possessive_Noun_Phrases'].notnull() & lang_df['25A_Locus_of_Marking:_Whole-language_Typology'].notnull() & lang_df['25B_Zero_Marking_of_A_and_P_Arguments'].notnull()& lang_df['26A_Prefixing_vs._Suffixing_in_Inflectional_Morphology'].notnull() \n",
    "& lang_df['27A_Reduplication'].notnull() & lang_df['28A_Case_Syncretism'].notnull() & lang_df['29A_Syncretism_in_Verbal_Person/Number_Marking'].notnull()]\n",
    "\n",
    "x1 = df2['23A_Locus_of_Marking_in_the_Clause'].str[0]\n",
    "x1 = pd.to_numeric(x1)\n",
    "x2 = df2['24A_Locus_of_Marking_in_Possessive_Noun_Phrases'].str[0]\n",
    "x2 = pd.to_numeric(x2)\n",
    "x3 = df2['25A_Locus_of_Marking:_Whole-language_Typology'].str[0]\n",
    "x3 = pd.to_numeric(x3)\n",
    "x4 = df2['25B_Zero_Marking_of_A_and_P_Arguments'].str[0]\n",
    "x4 = pd.to_numeric(x4)\n",
    "x5 = df2['26A_Prefixing_vs._Suffixing_in_Inflectional_Morphology'].str[0]\n",
    "x5 = pd.to_numeric(x5)                \n",
    "x6 = df2['27A_Reduplication'].str[0]\n",
    "x6 = pd.to_numeric(x6)\n",
    "x7 = df2['28A_Case_Syncretism'].str[0]\n",
    "x7 = pd.to_numeric(x7)\n",
    "x8 = df2['29A_Syncretism_in_Verbal_Person/Number_Marking'].str[0]\n",
    "x8 = pd.to_numeric(x8)\n",
    "\n",
    "#convert all series to list data structures\n",
    "x1 = pd.Series.tolist(x1)\n",
    "x2 = pd.Series.tolist(x2)\n",
    "x3 = pd.Series.tolist(x3)\n",
    "x4 = pd.Series.tolist(x4)\n",
    "x5 = pd.Series.tolist(x5)\n",
    "x6 = pd.Series.tolist(x6)\n",
    "x7 = pd.Series.tolist(x7)\n",
    "x8 = pd.Series.tolist(x8)\n",
    "\n",
    "F = []\n",
    "for i in range(0, len(x1)):\n",
    "    F.append([])\n",
    "for i in range(0, len(x1)):\n",
    "    F[i].append(x1[i])\n",
    "    F[i].append(x2[i])\n",
    "    F[i].append(x3[i])\n",
    "    F[i].append(x4[i])\n",
    "    F[i].append(x5[i])\n",
    "    F[i].append(x6[i])\n",
    "    F[i].append(x7[i])\n",
    "    F[i].append(x8[i])\n",
    "    \n",
    "P = pd.Series.tolist(df2['Climate'])\n",
    "for i in range(0,len(P)):\n",
    "    if P[i][2] == 'A':\n",
    "        P[i] = 1\n",
    "    elif P[i][2] == 'B':\n",
    "        P[i] = 2\n",
    "    elif P[i][2] == 'C':\n",
    "        P[i] = 3\n",
    "    elif P[i][2] == 'D':\n",
    "        P[i] = 4\n",
    "    elif P[i][2] == 'E':\n",
    "        P[i] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classify = OneVsRestClassifier(estimator=SVC(random_state=0))\n",
    "\n",
    "predic = classify.fit(F, P).predict(F)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   1   2   3  4  5\n",
       "Actual                     \n",
       "1          26   1   2  0  0\n",
       "2           4  11   3  0  0\n",
       "3           5   1  23  0  0\n",
       "4           2   1   3  6  0\n",
       "5           0   0   0  0  3"
      ]
     },
     "execution_count": 782,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actu = pd.Series(P, name='Actual')\n",
    "y_pred = pd.Series(predic, name='Predicted')\n",
    "confusion = pd.crosstab(y_actu, y_pred)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7582417582417582"
      ]
     },
     "execution_count": 784,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I think SVM overfits?\n",
    "c=0\n",
    "for i in range(0, len(P)):\n",
    "    if P[i]== predic[i]:\n",
    "        c=c+1\n",
    "c/len(P)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 795,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_f, test_f, train_p, test_p = train_test_split(F,P)\n",
    "trained_mod = RFC(train_f, train_p)\n",
    "trained_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy ::  0.897058823529\n",
      "Test Accuracy  ::  0.391304347826\n"
     ]
    }
   ],
   "source": [
    "predictions = trained_mod.predict(test_f)\n",
    "print(\"Train Accuracy :: \", accuracy_score(train_p, trained_mod.predict(train_f)))\n",
    "print(\"Test Accuracy  :: \", accuracy_score(test_p, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
